<h1>Project Description:</h1>
<p>I'm plan to made a local App integrated in AI to help designer to make highly customized UI, and implement several ready-made UI component in it, and make different categories.
I'll try to using computer vision learning and train a data set to tell LLM to select, create UI component in different style, and give user recommendation depends on which type of App that user wants to create.

  I think in frontend design, if during the dev, a Global-Vision Design Agent could change how it work when doing the dev.
</p>

<h2>Step1. Data Research</h2>
<p>1. Find different Data on how many Apps we have nowadays.\n

  2. How to make LLM much better in recognize vision contents.\n

3. What vivid effects look like (visual patterns)\n

4. How vivid effects are constructed (CSS, components, tokens)\n

5. Why & when to use them (UX reasoning)</p>


<h2>===Generated part by GPT, But that's the point===</h2>
ğŸ”® 2. What a Global-Vision Design Agent Must Understand

To achieve vivid, interactive UI creation, the agent must learn:

A. Spatial context

â€œWhere does this element exist in the visual hierarchy?â€

B. Temporal context

â€œHow do elements change over time when interacted with?â€

C. Style coherence

â€œWhat is the global design system implied by this page?â€

D. User intention simulation

â€œHow does a user perceive vividness / depth / energy?â€

E. Brand storytelling

â€œWhat emotional tone should this interface emit?â€

This agent is essentially a designer.
